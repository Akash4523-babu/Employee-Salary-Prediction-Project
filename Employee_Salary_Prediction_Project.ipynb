{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLkpeQRI81OzmDubApNeAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akash4523-babu/Employee-Salary-Prediction-Project/blob/main/Employee_Salary_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y0oKPqRXMhV",
        "outputId": "a7bd0769-b391-4b20-b81f-ef660c043a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
            "0   25    Private  226802          11th                7       Never-married   \n",
            "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
            "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
            "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
            "4   18          ?  103497  Some-college               10       Never-married   \n",
            "\n",
            "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
            "1    Farming-fishing      Husband  White    Male             0             0   \n",
            "2    Protective-serv      Husband  White    Male             0             0   \n",
            "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
            "4                  ?    Own-child  White  Female             0             0   \n",
            "\n",
            "   hours-per-week native-country income  \n",
            "0              40  United-States  <=50K  \n",
            "1              50  United-States  <=50K  \n",
            "2              40  United-States   >50K  \n",
            "3              40  United-States   >50K  \n",
            "4              30  United-States  <=50K  \n",
            "Initial data shape: (48842, 15)\n",
            "\n",
            "Missing values (represented by '?'):\n",
            "'workclass': 2799 '?' values\n",
            "'occupation': 2809 '?' values\n",
            "'native-country': 857 '?' values\n",
            "\n",
            "Data shape after cleaning: (46120, 15)\n",
            "\n",
            "--- Preprocessing Output Diagnostic ---\n",
            "Type of X_train_processed: <class 'scipy.sparse._csr.csr_matrix'>\n",
            "X_train_processed is a sparse matrix. Converting to dense for dtype check.\n",
            "dtype of X_train_processed (dense): float64\n",
            "Shape of X_train_processed (dense): (36896, 101)\n",
            "--- End Preprocessing Output Diagnostic ---\n",
            "\n",
            "Training LogisticRegression...\n",
            "LogisticRegression Accuracy: 0.8443\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.87      0.93      0.90      6906\n",
            "        >50K       0.73      0.60      0.66      2318\n",
            "\n",
            "    accuracy                           0.84      9224\n",
            "   macro avg       0.80      0.76      0.78      9224\n",
            "weighted avg       0.84      0.84      0.84      9224\n",
            "\n",
            "\n",
            "Training RandomForest...\n",
            "RandomForest Accuracy: 0.8502\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.93      0.90      6906\n",
            "        >50K       0.74      0.63      0.68      2318\n",
            "\n",
            "    accuracy                           0.85      9224\n",
            "   macro avg       0.81      0.78      0.79      9224\n",
            "weighted avg       0.84      0.85      0.85      9224\n",
            "\n",
            "\n",
            "Training KNN...\n",
            "KNN Accuracy: 0.8294\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.87      0.90      0.89      6906\n",
            "        >50K       0.68      0.62      0.64      2318\n",
            "\n",
            "    accuracy                           0.83      9224\n",
            "   macro avg       0.78      0.76      0.77      9224\n",
            "weighted avg       0.82      0.83      0.83      9224\n",
            "\n",
            "\n",
            "Training SVM...\n",
            "SVM Accuracy: 0.8503\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.87      0.94      0.90      6906\n",
            "        >50K       0.77      0.58      0.66      2318\n",
            "\n",
            "    accuracy                           0.85      9224\n",
            "   macro avg       0.82      0.76      0.78      9224\n",
            "weighted avg       0.84      0.85      0.84      9224\n",
            "\n",
            "\n",
            "Training GradientBoosting...\n",
            "GradientBoosting Accuracy: 0.8618\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.95      0.91      6906\n",
            "        >50K       0.80      0.60      0.69      2318\n",
            "\n",
            "    accuracy                           0.86      9224\n",
            "   macro avg       0.84      0.78      0.80      9224\n",
            "weighted avg       0.86      0.86      0.85      9224\n",
            "\n",
            "\n",
            "‚úÖ Best model: GradientBoosting with accuracy 0.8618\n",
            "‚úÖ Saved best model as best_model.pkl\n",
            "‚úÖ Saved preprocessor as preprocessing.pkl\n",
            "\n",
            "Model training and saving complete. You can now use these .pkl files for deployment.\n"
          ]
        }
      ],
      "source": [
        "# Step 0: Install necessary libraries (if not already installed in your Colab/Jupyter environment)\n",
        "# !pip install pandas scikit-learn joblib matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for checking array types\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Good for EDA plots\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# --- Step 1: Load Dataset ---\n",
        "try:\n",
        "    data = pd.read_csv(\"Dataset.csv\")\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    print(data.head())\n",
        "    print(f\"Initial data shape: {data.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset.csv not found. Please ensure it's in the correct directory.\")\n",
        "    # Exit or handle the error appropriately\n",
        "    exit()\n",
        "\n",
        "# --- Step 2: Exploratory Data Analysis (EDA) and Cleaning ---\n",
        "\n",
        "# Check for missing values (represented by '?' in this dataset)\n",
        "print(\"\\nMissing values (represented by '?'):\")\n",
        "for column in data.columns:\n",
        "    if '?' in data[column].unique():\n",
        "        print(f\"'{column}': {data[column].value_counts().get('?', 0)} '?' values\")\n",
        "\n",
        "# Handle '?' values by replacing them with 'Others' or by dropping rows/columns as per previous steps\n",
        "# Based on your notebook, you replaced '?' with 'Others' for specific columns\n",
        "data['workclass'] = data['workclass'].replace('?', 'Others')\n",
        "data['occupation'] = data['occupation'].replace('?', 'Others')\n",
        "data['native-country'] = data['native-country'].replace('?', 'Others')\n",
        "\n",
        "# Removing specific rows based on your previous notebook's EDA\n",
        "# (These were rows with very few counts or considered outliers based on domain knowledge)\n",
        "data = data[data['workclass'] != 'Without-pay']\n",
        "data = data[data['workclass'] != 'Never-worked']\n",
        "data = data[data['occupation'] != 'Armed-Forces']\n",
        "data = data[data['education'] != 'Preschool']\n",
        "data = data[data['education'] != '1st-4th']\n",
        "data = data[data['education'] != '5th-6th']\n",
        "\n",
        "# Outlier detection based on your notebook's box plots\n",
        "# age: Filtered (age <= 75 and age >= 18)\n",
        "data = data[(data['age'] <= 75) & (data['age'] >= 18)]\n",
        "# educational-num: Filtered (educational-num <= 16 and educational-num >= 5)\n",
        "data = data[(data['educational-num'] <= 16) & (data['educational-num'] >= 5)]\n",
        "# (capital-gain and capital-loss were not filtered in the notebook, but boxplots were shown,\n",
        "# suggesting they were left as is or handled by scaling)\n",
        "# (hours-per-week was not filtered in the notebook, but boxplots were shown, suggesting it was left as is or handled by scaling)\n",
        "\n",
        "print(f\"\\nData shape after cleaning: {data.shape}\")\n",
        "\n",
        "# --- Step 3: Define Features (X) and Target (y) ---\n",
        "X = data.drop(columns=['income'])\n",
        "y = data['income']\n",
        "\n",
        "# --- Step 4: Preprocessing (Numerical and Categorical Feature Handling) ---\n",
        "\n",
        "# Identify numerical and categorical columns from the original X\n",
        "# Make sure these lists are accurate for your dataset's column names\n",
        "numerical_features = [\n",
        "    'age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week'\n",
        "]\n",
        "categorical_features = [\n",
        "    'workclass', 'education', 'marital-status', 'occupation',\n",
        "    'relationship', 'race', 'gender', 'native-country'\n",
        "]\n",
        "\n",
        "# Create a ColumnTransformer for preprocessing\n",
        "# Numerical features will be scaled\n",
        "# Categorical features will be One-Hot Encoded (from their string values)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep any other columns not specified (e.g., if there were others)\n",
        ")\n",
        "\n",
        "# --- Step 5: Train-Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Step 6: Apply Preprocessing to Training and Test Data ---\n",
        "# Fit the preprocessor on X_train and transform both X_train and X_test\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# --- DIAGNOSTIC STEP (Crucial to verify preprocessing output) ---\n",
        "print(\"\\n--- Preprocessing Output Diagnostic ---\")\n",
        "print(f\"Type of X_train_processed: {type(X_train_processed)}\")\n",
        "if hasattr(X_train_processed, 'toarray'): # Check if it's a sparse matrix\n",
        "    print(\"X_train_processed is a sparse matrix. Converting to dense for dtype check.\")\n",
        "    dense_array = X_train_processed.toarray()\n",
        "    print(f\"dtype of X_train_processed (dense): {dense_array.dtype}\")\n",
        "    print(f\"Shape of X_train_processed (dense): {dense_array.shape}\")\n",
        "    if not np.issubdtype(dense_array.dtype, np.number):\n",
        "        print(\"WARNING: Data still contains non-numeric types after preprocessing!\")\n",
        "        print(dense_array[:2, :5]) # Print first 2 rows, first 5 columns for inspection\n",
        "else: # It's likely already a dense array (e.g., if no OneHotEncoding resulted in sparse output)\n",
        "    print(f\"dtype of X_train_processed: {X_train_processed.dtype}\")\n",
        "    print(f\"Shape of X_train_processed: {X_train_processed.shape}\")\n",
        "    if not np.issubdtype(X_train_processed.dtype, np.number):\n",
        "        print(\"WARNING: Data still contains non-numeric types after preprocessing!\")\n",
        "        print(X_train_processed[:2, :5]) # Print first 2 rows, first 5 columns for inspection\n",
        "\n",
        "print(\"--- End Preprocessing Output Diagnostic ---\")\n",
        "\n",
        "# --- Step 7: Train and Evaluate Models ---\n",
        "# The models now receive the already processed (numerical) data\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000), # Increased max_iter for convergence\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train_processed, y_train)\n",
        "    y_pred = model.predict(X_test_processed) # Predict on processed data\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = acc\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_model = model\n",
        "        best_model_name = name\n",
        "\n",
        "print(f\"\\n‚úÖ Best model: {best_model_name} with accuracy {best_accuracy:.4f}\")\n",
        "\n",
        "# --- Step 8: Save Best Model and Preprocessor ---\n",
        "# Save the best trained model\n",
        "joblib.dump(best_model, \"best_model.pkl\")\n",
        "print(\"‚úÖ Saved best model as best_model.pkl\")\n",
        "\n",
        "# Save the fitted preprocessor\n",
        "joblib.dump(preprocessor, \"preprocessing.pkl\")\n",
        "print(\"‚úÖ Saved preprocessor as preprocessing.pkl\")\n",
        "\n",
        "print(\"\\nModel training and saving complete. You can now use these .pkl files for deployment.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Set Streamlit page configuration\n",
        "st.set_page_config(page_title=\"Employee Salary Classification\", page_icon=\"üíº\", layout=\"centered\")\n",
        "\n",
        "# --- Load the trained model and preprocessor ---\n",
        "try:\n",
        "    model = joblib.load(\"best_model.pkl\")\n",
        "    preprocessor = joblib.load(\"preprocessing.pkl\")\n",
        "    st.success(\"Model and preprocessor loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    st.error(\"Error: 'best_model.pkl' or 'preprocessing.pkl' not found. Please ensure they are in the same directory as app.py.\")\n",
        "    st.stop() # Stop the app if essential files are missing\n",
        "except Exception as e:\n",
        "    st.error(f\"An error occurred loading the model/preprocessor: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "st.title(\"üíº Employee Salary Classification App\")\n",
        "st.markdown(\"Predict whether an employee earns **>50K** or **‚â§50K** based on input features.\")\n",
        "\n",
        "# --- Sidebar inputs for user to provide details ---\n",
        "st.sidebar.header(\"Input Employee Details\")\n",
        "\n",
        "# Define ranges and options based on your EDA and original dataset unique values\n",
        "# Numerical inputs\n",
        "age = st.sidebar.slider(\"Age\", 18, 75, 30)\n",
        "hours_per_week = st.sidebar.slider(\"Hours per week\", 1, 99, 40)\n",
        "capital_gain = st.sidebar.number_input(\"Capital Gain\", min_value=0, max_value=99999, value=0)\n",
        "capital_loss = st.sidebar.number_input(\"Capital Loss\", min_value=0, max_value=4356, value=0) # Max based on your EDA\n",
        "fnlwgt = st.sidebar.number_input(\"Final Weight (fnlwgt)\", min_value=12285, max_value=1490400, value=190000) # Range based on EDA\n",
        "educational_num = st.sidebar.slider(\"Educational Number\", 5, 16, 9) # Range based on your EDA\n",
        "\n",
        "# Categorical inputs (using selectbox for string values)\n",
        "workclass = st.sidebar.selectbox(\"Workclass\", [\n",
        "    \"Private\", \"Self-emp-not-inc\", \"Local-gov\", \"Others\", \"State-gov\",\n",
        "    \"Self-emp-inc\", \"Federal-gov\"\n",
        "])\n",
        "education = st.sidebar.selectbox(\"Education Level\", [\n",
        "    \"Bachelors\", \"Masters\", \"Doctorate\", \"HS-grad\", \"Assoc-acdm\", \"Some-college\",\n",
        "    \"11th\", \"10th\", \"7th-8th\", \"Prof-school\", \"9th\", \"12th\", \"Assoc-voc\"\n",
        "])\n",
        "marital_status = st.sidebar.selectbox(\"Marital Status\", [\n",
        "    \"Married-civ-spouse\", \"Never-married\", \"Divorced\", \"Separated\",\n",
        "    \"Widowed\", \"Married-spouse-absent\", \"Married-AF-spouse\"\n",
        "])\n",
        "occupation = st.sidebar.selectbox(\"Job Role\", [\n",
        "    \"Prof-specialty\", \"Craft-repair\", \"Exec-managerial\", \"Adm-clerical\", \"Sales\",\n",
        "    \"Other-service\", \"Machine-op-inspct\", \"Others\", \"Transport-moving\",\n",
        "    \"Handlers-cleaners\", \"Farming-fishing\", \"Tech-support\", \"Protective-serv\",\n",
        "    \"Priv-house-serv\"\n",
        "])\n",
        "relationship = st.sidebar.selectbox(\"Relationship\", [\n",
        "    \"Husband\", \"Not-in-family\", \"Own-child\", \"Unmarried\", \"Wife\", \"Other-relative\"\n",
        "])\n",
        "race = st.sidebar.selectbox(\"Race\", [\n",
        "    \"White\", \"Black\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\"\n",
        "])\n",
        "gender = st.sidebar.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
        "native_country = st.sidebar.selectbox(\"Native Country\", [\n",
        "    \"United-States\", \"Mexico\", \"Others\", \"Philippines\", \"Germany\", \"Puerto-Rico\",\n",
        "    \"Canada\", \"El-Salvador\", \"India\", \"Cuba\", \"England\", \"China\", \"South\",\n",
        "    \"Jamaica\", \"Italy\", \"Dominican-Republic\", \"Japan\", \"Guatemala\", \"Poland\",\n",
        "    \"Vietnam\", \"Columbia\", \"Haiti\", \"Portugal\", \"Taiwan\", \"Iran\", \"Nicaragua\",\n",
        "    \"Greece\", \"Peru\", \"Ecuador\", \"France\", \"Ireland\", \"Thailand\", \"Hong\",\n",
        "    \"Cambodia\", \"Trinadad&Tobago\", \"Laos\", \"Outlying-US(Guam-USVI-etc)\",\n",
        "    \"Yugoslavia\", \"Scotland\", \"Honduras\", \"Hungary\", \"Holand-Netherlands\"\n",
        "])\n",
        "\n",
        "\n",
        "# --- Build input DataFrame for single prediction ---\n",
        "# IMPORTANT: The order of columns in this DataFrame MUST exactly match the original 'X' DataFrame\n",
        "# used to train the preprocessor in the notebook.\n",
        "# This order was: ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "#                   'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "#                   'hours-per-week', 'native-country']\n",
        "input_data = {\n",
        "    'age': [age],\n",
        "    'workclass': [workclass],\n",
        "    'fnlwgt': [fnlwgt],\n",
        "    'education': [education],\n",
        "    'educational-num': [educational_num],\n",
        "    'marital-status': [marital_status],\n",
        "    'occupation': [occupation],\n",
        "    'relationship': [relationship],\n",
        "    'race': [race],\n",
        "    'gender': [gender],\n",
        "    'capital-gain': [capital_gain],\n",
        "    'capital-loss': [capital_loss],\n",
        "    'hours-per-week': [hours_per_week],\n",
        "    'native-country': [native_country]\n",
        "}\n",
        "\n",
        "input_df = pd.DataFrame(input_data)\n",
        "\n",
        "st.write(\"### üîé Input Data\")\n",
        "st.write(input_df)\n",
        "\n",
        "# --- Predict button for single prediction ---\n",
        "if st.button(\"Predict Salary Class\"):\n",
        "    try:\n",
        "        # Preprocess the input data\n",
        "        processed_input = preprocessor.transform(input_df)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(processed_input)\n",
        "\n",
        "        st.success(f\"‚úÖ Prediction: Employee Salary is {prediction[0]}\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"An error occurred during prediction: {e}\")\n",
        "        st.info(\"Please check the input values and ensure the model is correctly loaded.\")\n",
        "\n",
        "# --- Batch prediction ---\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"#### üìÇ Batch Prediction\")\n",
        "uploaded_file = st.file_uploader(\"Upload a CSV file for batch prediction\", type=\"csv\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    batch_data = pd.read_csv(uploaded_file)\n",
        "    st.write(\"Uploaded data preview:\", batch_data.head())\n",
        "\n",
        "    # Ensure the batch_data columns match the training data columns exactly\n",
        "    # You might want to add more robust error handling or data cleaning for batch uploads\n",
        "    # e.g., checking for missing columns, handling '?' values, etc.\n",
        "\n",
        "    try:\n",
        "        # Preprocess the batch data\n",
        "        processed_batch_data = preprocessor.transform(batch_data)\n",
        "\n",
        "        # Make predictions\n",
        "        batch_preds = model.predict(processed_batch_data)\n",
        "        batch_data['PredictedClass'] = batch_preds\n",
        "\n",
        "        st.write(\"‚úÖ Predictions:\")\n",
        "        st.write(batch_data.head())\n",
        "\n",
        "        # Provide download button for predictions\n",
        "        csv = batch_data.to_csv(index=False).encode('utf-8')\n",
        "        st.download_button(\n",
        "            \"Download Predictions CSV\",\n",
        "            csv,\n",
        "            file_name='predicted_classes.csv',\n",
        "            mime='text/csv'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.error(f\"An error occurred during batch prediction: {e}\")\n",
        "        st.info(\"Please ensure the uploaded CSV has the correct columns and data format as the original dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEZlRoWhYX2H",
        "outputId": "53714b2f-a67e-45c5-9ea9-269d39039eca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ecd517",
        "outputId": "9bebd294-c34b-48d8-fa55-c9ea76d0bd43"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ]
    }
  ]
}